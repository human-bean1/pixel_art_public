{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04e347fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixels #\n",
      "3700\n",
      "distant matrix:\n",
      "[[ 0.          0.36353092  1.30998208 ... 74.28180156 73.21147831\n",
      "  73.21147831]\n",
      " [ 0.36353092  0.          1.0083307  ... 73.91845294 72.84822351\n",
      "  72.84822351]\n",
      " [ 1.30998208  1.0083307   0.         ... 73.12912668 72.05403744\n",
      "  72.05403744]\n",
      " ...\n",
      " [74.28180156 73.91845294 73.12912668 ...  0.          1.23516018\n",
      "   1.23516018]\n",
      " [73.21147831 72.84822351 72.05403744 ...  1.23516018  0.\n",
      "   0.        ]\n",
      " [73.21147831 72.84822351 72.05403744 ...  1.23516018  0.\n",
      "   0.        ]]\n",
      "Raw assignment expectations:\n",
      "[[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "\n",
      "Ideal clustering results:\n",
      "[[ True False]\n",
      " [ True False]\n",
      " [ True False]\n",
      " ...\n",
      " [False  True]\n",
      " [False  True]\n",
      " [False  True]]\n"
     ]
    }
   ],
   "source": [
    "# Test to represent a small barack image as two subclusters based on color\n",
    "# notes: medium barack image uses too much memory/breaks\n",
    "\n",
    "import numpy as np\n",
    "from detan.detan import AssignmentAnnealing, assignment_iteration\n",
    "from skimage import io, color\n",
    "# from sklearn.metrics import pairwise_distances\n",
    "from scipy.spatial import distance_matrix\n",
    "\n",
    "# read the input RGB image\n",
    "# rgb = io.imread(\"barack-2.jpg\",plugin='matplotlib')\n",
    "rgb = io.imread(\"barack-3.jpg\",plugin='matplotlib')\n",
    "\n",
    "# print(rgb.shape)\n",
    "\n",
    "# convert RGB to LAB\n",
    "img = color.rgb2lab(rgb)\n",
    "\n",
    "img_h = img.shape[0] # Image Height\n",
    "img_w = img.shape[1] # Image Width\n",
    "\n",
    "N = img_h * img_w  # Total number of pixels in the image\n",
    "print(\"pixels #\")\n",
    "print(N)\n",
    "flat_img = img.reshape((N,3))\n",
    "\n",
    "# take in a group of pixels, and sort them into two sub-clusters based on color\n",
    "\n",
    "# function to calculate distances between each pixel \n",
    "# pairwise_distances(flat_img,img,metric=\"euclidean\")\n",
    "dist_mat = distance_matrix(flat_img, flat_img, p=2)\n",
    "print(\"distant matrix:\")\n",
    "print(dist_mat)\n",
    "\n",
    "distances = dist_mat\n",
    "\n",
    "# # decide how many groups there are\n",
    "groups = 2\n",
    "\n",
    "# # The initial assignment expectations should be random, and must sum to 1 across\n",
    "# # each row. There should be no identical entries in a given row.\n",
    "initial_assignments = 0.5 + 0.1 * (np.random.random((N,groups)) - 0.5)\n",
    "row_sum = np.tile(initial_assignments.sum(1), (groups, 1)).T\n",
    "initial_assignments = initial_assignments/row_sum\n",
    "\n",
    "# # This is the state of our annealling.\n",
    "annealer = AssignmentAnnealing(assignment_iteration(distances), initial_assignments, 0.73)\n",
    "\n",
    "# # Tolerance for deciding when to lower the temperature. We also need to keep\n",
    "# # track of the old assignments.\n",
    "tolerance = 1e-6\n",
    "old_assignments = initial_assignments\n",
    "\n",
    "# # For the sake of simplicity, I've picked an arbitrary number of temperature\n",
    "# # steps.\n",
    "# ^change temp to variance\n",
    "\n",
    "for _ in range(10): # 10 works fine, 20 breaks code w/ NaN's\n",
    "    # Iterating over the annealer object produces the new assignment\n",
    "    # expectations.\n",
    "    for new_assignments in annealer:\n",
    "        # If none of the assignments change by more than the tolerance, drop the\n",
    "        # temperature.\n",
    "        if np.abs(new_assignments - old_assignments).max() < tolerance:\n",
    "            break\n",
    "        old_assignments = new_assignments\n",
    "    # Next temperature.\n",
    "    annealer.cool()\n",
    "\n",
    "# The raw assignment expectation values.\n",
    "print(\"Raw assignment expectations:\")\n",
    "print(annealer.assignments)\n",
    "\n",
    "print()\n",
    "\n",
    "# The \"ideal\" clustering results.\n",
    "print(\"Ideal clustering results:\")\n",
    "print(annealer.assignments > 1e-50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "43c8c2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data processing \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# # Visualization\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# Dataset\n",
    "from sklearn import datasets\n",
    "# Dimensionality reduction\n",
    "# from sklearn.decomposition import PCA\n",
    "# from sklearn.manifold import TSNE\n",
    "# Modeling\n",
    "# from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "# from sklearn.mixture import GaussianMixture\n",
    "# from sklearn.cluster import DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b71396cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "iris = datasets.load_iris()\n",
    "# Show data information\n",
    "iris.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39448570",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The feature names are: ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']\n",
      "The target names are: ['setosa' 'versicolor' 'virginica']\n",
      "The target values are: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Print feature and target information\n",
    "print('The feature names are:', iris['feature_names'])\n",
    "print('The target names are:', iris['target_names'])\n",
    "print('The target values are:', iris['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d4d9504d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   sepal length (cm)  150 non-null    float64\n",
      " 1   sepal width (cm)   150 non-null    float64\n",
      " 2   petal length (cm)  150 non-null    float64\n",
      " 3   petal width (cm)   150 non-null    float64\n",
      " 4   target             150 non-null    int32  \n",
      "dtypes: float64(4), int32(1)\n",
      "memory usage: 5.4 KB\n"
     ]
    }
   ],
   "source": [
    "# Put features data into a dataframe\n",
    "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
    "# Add target to the dataframe \n",
    "df['target'] = iris.target\n",
    "# Data information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00478c3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    50\n",
       "1    50\n",
       "2    50\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check counts of each category\n",
    "df['target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fe406bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove target for the clustering model\n",
    "X = df[df.columns.difference(['target'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56d96108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "1    50\n",
       "2    36\n",
       "Name: y_hc, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hierachical clustering model\n",
    "hc = AgglomerativeClustering(n_clusters = 3)\n",
    "# Fit and predict on the data\n",
    "y_hc = hc.fit_predict(X)\n",
    "# Save the predictions as a column\n",
    "df['y_hc']=y_hc\n",
    "# Check the distribution\n",
    "df['y_hc'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00e9129",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
